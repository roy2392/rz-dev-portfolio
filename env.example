# Backend
UVICORN_IP=0.0.0.0
UVICORN_PORT=8000
# I'm using https://requesty.ai/ for an LLM router but you can use the default: https://api.openai.com/v1
LLM_ROUTER_URL="https://router.requesty.ai/v1"
LLM_ROUTER_API_KEY=<your-api-key>
# Change this to an OpenAI model if not using requesty.ai
LLM_MODEL="anthropic/claude-3-5-sonnet-latest" 
EMBEDDING_MODEL="text-embedding-3-small"
OPENAI_API_KEY=<your-openai-api-key>
FRONTEND_URL=http://localhost:5173

# Postgres
POSTGRES_SERVER=localhost
POSTGRES_PORT=5432
POSTGRES_DB=pgdb
POSTGRES_USER=pguser
POSTGRES_PASSWORD=docker

# Redis and Rate Limiting
REDIS_URL=redis://localhost:6379
GLOBAL_RATE_LIMIT=1000/hour
CHAT_RATE_LIMIT=30/minute

# Frontend
VITE_BACKEND_URL=http://localhost:8000 